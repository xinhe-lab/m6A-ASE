{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASE calling pipeline\n",
    "\n",
    "Mostly based on Yanyu's work in 2017. The pipeline aligns `fastq` sequences to `bam` using `STAR`, then adjust the mapping via `WASP` to account for allele specificity, and finally call genotype and ASE via `QuASAR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of procedure\n",
    "\n",
    "1. Gather require resources\n",
    "2. Align reads to genome\n",
    "3. Remove biased reads\n",
    "4. Genotype and ASE calling\n",
    "\n",
    "The pipeline is implemented in SoS as displayed in the rest of this SoS notebook. The pipeline can be executed from this notebook directly on local or remote computer. For more information see [SoS website](https://github.com/vatlab/SOS).\n",
    "\n",
    "To run the pipeline:\n",
    "\n",
    "```\n",
    "sos run nb.ipynb hg19_reference\n",
    "sos run nb.ipynb obtain_samples\n",
    "sos run nb.ipynb align\n",
    "sos run nb.ipynb call\n",
    "sos run nb.ipynb quasar\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "cwd = path('~/Documents/m6A/Data/ASE')\n",
    "parameter: ncpu = 20\n",
    "# Resource files\n",
    "resource_dir = f\"{cwd:a}/hg19\"\n",
    "ref_fa = \"hg19.fa\"\n",
    "ref_gtf = 'Homo_sapiens.GRCh38.91.gtf.gz'\n",
    "wasp_dir = f\"{cwd:a}/WASP-master/mapping\"\n",
    "# Sample files\n",
    "sample_dir = f\"{cwd:a}/samples\"\n",
    "from collections import OrderedDict\n",
    "## A list of sample names (keys) and their corresponding FASTQ files (values)\n",
    "samples = OrderedDict({'ENCLB279NMT': ['ENCFF824TZM', 'ENCFF176JNE']})\n",
    "fastq = paths([[f\"{sample_dir}/{s}/{q}.fastq.gz\" for q in samples[s]] for s in samples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource preparation\n",
    "\n",
    "### hg19 human reference data\n",
    "\n",
    "Obtain `hg19.fa` and `Homo_sapiens.GRCh38.91.gtf.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[hg19_reference_1 (download)]\n",
    "# Download `hg19.2bit` and `twoBitToFa` from {ucsc_url}\n",
    "ucsc_url = \"http://hgdownload.cse.ucsc.edu\"\n",
    "output: f\"{resource_dir}/hg19.2bit\", f\"{resource_dir}/twoBitToFa\"\n",
    "download: dest_dir = resource_dir, expand = True\n",
    "    {ucsc_url}/goldenPath/hg19/bigZips/hg19.2bit\n",
    "    {ucsc_url}/admin/exe/linux.x86_64/twoBitToFa\n",
    "\n",
    "[hg19_reference_2 (decompress hg19.fa)]\n",
    "# Use `twoBitToFa` to extract `hg19.fa` from `hg19.2bit`\n",
    "output: f\"{resource_dir}/{ref_fa}\"\n",
    "bash: expand = True\n",
    "    chmod +x {_input[1]}\n",
    "    {_input[1]} {_input[0]} {_output}\n",
    "\n",
    "[hg19_reference_3 (gene annotations)]\n",
    "# Download `Homo_sapiens.GRCh38.91.gtf.gz` from Ensembl\n",
    "# https://useast.ensembl.org/info/data/ftp/index.html\n",
    "ensembl_ftp = 'ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/'\n",
    "output: f\"{resource_dir}/{ref_gtf}\"\n",
    "download: dest_dir = resource_dir, expand = True\n",
    "    {ensembl_ftp}/{ref_gtf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally `WASP` uses pre-defined list of SNPs and removes bias caused by them. The list was generated by Yanyu using 1k genome SNP in VCF format with MAF filter as input to `WASP/mapping/extract_vcf_snps.sh` command. Here I just take this pre-compiled list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[wasp]\n",
    "output: f\"{wasp_dir}/README.md\"\n",
    "download: decompress = True, dest_file = f'{cwd:a}/WASP.zip'\n",
    "    https://github.com/bmvdgeijn/WASP/archive/master.zip\n",
    "bash: expand = True\n",
    "    rm -f {cwd}/WASP.zip\n",
    "\n",
    "[star]\n",
    "# Quite time & resource consuming (3hrs, 32GB memory)\n",
    "depends: Py_Module('docker')\n",
    "output: f\"{resource_dir}/genomeParameters.txt\"\n",
    "bash: workdir = f'{cwd:a}', docker_image = 'bschiffthaler/ngs', expand=True\n",
    "     STAR --runMode genomeGenerate \\\n",
    "        --genomeDir {resource_dir} \\\n",
    "        --genomeFastaFiles {resource_dir}/{ref_fa} \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf} \\\n",
    "        --runThreadN {ncpu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also apparently `WASP` only works with Python 2 ... need to create a `conda` environment for it:\n",
    "\n",
    "```\n",
    "conda create -n py27 python=2.7\n",
    "source activate py27\n",
    "conda install pytables=2.4.0\n",
    "pip install pysam\n",
    "```\n",
    "\n",
    "and use \n",
    "\n",
    "```\n",
    "source activate py27\n",
    "```\n",
    "in `WASP` steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples\n",
    "\n",
    "FIXME: add description -- what are these samples?\n",
    "\n",
    "**Caution: these samples are paired end reads.** This is different from Yanyu's workflow and will impact `STAR` and `WASP` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[obtain_samples]\n",
    "# Download samples from ENCODE\n",
    "# https://www.encodeproject.org/experiments/ENCSR384KAN/\n",
    "encode_url = 'https://www.encodeproject.org/files'\n",
    "input: for_each = 'fastq', concurrent = True\n",
    "output: fastq, group_by = 1\n",
    "download: dest_dir = sample_dir, expand = True\n",
    "    {encode_url}/{_fastq:bnn}/@@download/{_fastq:b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefiltering alignment\n",
    "\n",
    "Align with `STAR`, followd by `samtools` to remove reads with quality less than given cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[align_1 (STAR prefiltering alignment)]\n",
    "parameter: qual_cutoff = 10\n",
    "depends: sos_step('star')\n",
    "input: fastq, group_by = 2, concurrent = True\n",
    "output: [f\"{sample_dir}/{x}.qual{qual_cutoff}.bam\" for x in samples], group_by = 1\n",
    "bash: workdir = f'{cwd:a}', docker_image = 'bschiffthaler/ngs', expand=True\n",
    "    STAR --genomeDir {resource_dir} \\\n",
    "        --readFilesIn {_input[0]} {_input[1]} \\\n",
    "        --readFilesCommand zcat \\\n",
    "        --runThreadN {ncpu} --outStd BAM_SortedByCoordinate \\\n",
    "        --outSAMtype BAM SortedByCoordinate \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf} |\n",
    "    samtools view -bq {qual_cutoff} > {_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WASP-informed remap\n",
    "\n",
    "Remap reads after [`WASP`](https://github.com/bmvdgeijn/WASP/tree/master/mapping) adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[align_2 (WASP intersecting SNP): shared = {'wasp_split': 'step_output'}]\n",
    "# WASP finding unbiased reads intersecting with SNP\n",
    "depends: sos_step('wasp')\n",
    "input: group_by = 1, concurrent = True\n",
    "output: [[f\"{x:n}.remap.fq1.gz\", f\"{x:n}.remap.fq2.gz\", f\"{x:n}.to.remap.bam\", f\"{x:n}.keep.bam\"] for x in _input], group_by = 4\n",
    "bash: workdir = f'{cwd:a}', expand = True\n",
    "    source activate py27\n",
    "    python {wasp_dir}/find_intersecting_snps.py {_input} \\\n",
    "        --snp_dir {resource_dir}/wasp_snp_list \\\n",
    "        --is_sorted --is_paired_end\n",
    "\n",
    "[align_3 (STAR post alignment)]\n",
    "# Align WASP remap with STAR\n",
    "# Followd by samtools remove reads with quality less than {qual_cutoff}\n",
    "parameter: qual_cutoff = 10\n",
    "input: group_by = 4, pattern = '{name}.{qual}.remap.{ext}', concurrent = True\n",
    "output: expand_pattern(f'{_name[0]}.remapped.qual{qual_cutoff}.bam')\n",
    "bash: workdir = f'{cwd:a}', docker_image = 'bschiffthaler/ngs', expand=True\n",
    "    STAR --genomeDir {resource_dir} \\\n",
    "        --readFilesIn {_input[0]} {_input[1]} \\\n",
    "        --readFilesCommand zcat \\\n",
    "        --runThreadN {ncpu} --outStd BAM_SortedByCoordinate \\\n",
    "        --outSAMtype BAM SortedByCoordinate \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf} |\n",
    "    samtools view -bq {qual_cutoff} > {_output}\n",
    "\n",
    "[align_4 (WASP remove ambiguously mapped reads)]\n",
    "to_remap = paths([wasp_split[i:i+4][2] for i in range(0, len(wasp_split), 4)])\n",
    "input: group_by = 1, paired_with = 'to_remap', pattern = '{name}.remapped.{ext}', concurrent = True\n",
    "output: expand_pattern(f'{_name[0]}.keep_remapped.{_ext[0]}')\n",
    "bash: workdir = f'{cwd:a}', expand=True\n",
    "    source activate py27\n",
    "    python {wasp_dir}/filter_remapped_reads.py {_input} {_to_remap} {_output}\n",
    "\n",
    "[align_5 (Merge WASP adjusted and originally kept BAM)]\n",
    "kept = paths([wasp_split[i:i+4][3] for i in range(0, len(wasp_split), 4)])\n",
    "input: group_by = 1, paired_with = 'kept', pattern = '{name}.keep_remapped.{ext}', concurrent = True\n",
    "output: expand_pattern(f'{_name[0]}.wasp_remapped.{_ext[0]}')\n",
    "bash: workdir = f'{cwd:a}', docker_image = 'bschiffthaler/ngs', expand=True\n",
    "    samtools merge - {_input} {_kept} | sort -o {_output}\n",
    "    samtools index {_output}\n",
    "\n",
    "[align_6 (WASP remove duplicate reads )]\n",
    "input: group_by = 1, pattern = '{name}.bam', concurrent = True\n",
    "output: expand_pattern(f'{_name[0]}.dedup.bam')\n",
    "bash: workdir = f'{cwd:a}', expand=True\n",
    "    source activate py27\n",
    "    python {wasp_dir}/rmdup.py {_input} {_output}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "python3",
     "python3",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
