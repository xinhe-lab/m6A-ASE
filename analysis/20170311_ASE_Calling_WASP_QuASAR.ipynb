{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASE calling pipeline\n",
    "\n",
    "Mostly based on Yanyu's work in 2017. The pipeline aligns `fastq` sequences to `bam` using `STAR`, then adjust the mapping via `WASP` to account for allele specificity, and finally call genotype and ASE via `QuASAR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of procedure\n",
    "\n",
    "1. Gather require resources\n",
    "2. Align reads to genome\n",
    "3. Remove biased reads\n",
    "4. Genotype and ASE calling\n",
    "\n",
    "The pipeline is implemented in SoS as displayed in the rest of this SoS notebook. The pipeline can be executed from this notebook directly on local or remote computer. For more information see [SoS website](https://github.com/vatlab/SOS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "cwd = path('~/Documents/ASE')\n",
    "# Resource files\n",
    "resource_dir = f\"{cwd:a}/hg19\"\n",
    "ref_fa = \"hg19.fa\"\n",
    "ref_gtf = 'Homo_sapiens.GRCh38.91.gtf.gz'\n",
    "wasp_dir = f\"{cwd:a}/WASP\"\n",
    "# Sample files\n",
    "sample_dir = f\"{cwd:a}/samples\"\n",
    "from collections import OrderedDict\n",
    "samples = OrderedDict({'ENCLB279NMT': ['ENCFF824TZM', 'ENCFF176JNE']})\n",
    "fastq = paths([[f\"{sample_dir}/{s}/{q}.fastq.gz\" for q in samples[s]] for s in samples])\n",
    "\n",
    "[wasp]\n",
    "output: f\"{wasp_dir}/README.md\"\n",
    "bash: work_dir = f'{cwd:a}'\n",
    "    git clone https://github.com/bmvdgeijn/WASP\n",
    "\n",
    "[star]\n",
    "# One time deal for all projects, quite time / resource consuming (32GB memory)\n",
    "parameter: ncpu = 2\n",
    "depends: Py_Module('docker')\n",
    "output: f\"{resource_dir}/genomeParameters.txt\"\n",
    "bash: docker_image = 'bschiffthaler/ngs', expand=True\n",
    "     STAR --runMode genomeGenerate \\\n",
    "        --genomeDir {resource_dir} \\\n",
    "        --genomeFastaFiles {resource_dir}/{ref_fa} \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf}\n",
    "        --runThreadN {ncpu}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resource preparation\n",
    "\n",
    "### hg19 human reference data\n",
    "\n",
    "Obtain `hg19.fa` and `Homo_sapiens.GRCh38.91.gtf.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[hg19_reference_1 (download)]\n",
    "# Download `hg19.2bit` and `twoBitToFa` from {ucsc_url}\n",
    "ucsc_url = \"http://hgdownload.cse.ucsc.edu\"\n",
    "output: f\"{resource_dir}/hg19.2bit\", f\"{resource_dir}/twoBitToFa\"\n",
    "download: dest_dir = resource_dir, expand = True\n",
    "    {ucsc_url}/goldenPath/hg19/bigZips/hg19.2bit\n",
    "    {ucsc_url}/admin/exe/linux.x86_64/twoBitToFa\n",
    "\n",
    "[hg19_reference_2 (decompress hg19.fa)]\n",
    "# Use `twoBitToFa` to extract `hg19.fa` from `hg19.2bit`\n",
    "output: f\"{resource_dir}/{ref_fa}\"\n",
    "bash: expand = True\n",
    "    chmod +x {_input[1]}\n",
    "    {_input[1]} {_input[0]} {_output}\n",
    "\n",
    "[hg19_reference_3 (gene annotations)]\n",
    "# Download `Homo_sapiens.GRCh38.91.gtf.gz` from Ensembl\n",
    "# https://useast.ensembl.org/info/data/ftp/index.html\n",
    "ensembl_ftp = 'ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/'\n",
    "output: f\"{resource_dir}/{ref_gtf}\"\n",
    "download: dest_dir = resource_dir, expand = True\n",
    "    {ensembl_ftp}/{ref_gtf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get samples\n",
    "\n",
    "FIXME: add description -- where do samples come from, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[obtain_samples]\n",
    "# Download samples from ENCODE\n",
    "# https://www.encodeproject.org/experiments/ENCSR384KAN/\n",
    "encode_url = 'https://www.encodeproject.org/files'\n",
    "input: for_each = 'fastq', concurrent = True\n",
    "output: fastq, group_by = 1\n",
    "download: dest_dir = sample_dir, expand = True\n",
    "    {encode_url}/{_fastq:bnn}/@@download/{_fastq:b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[align_1 (STAR prefiltering alignment)]\n",
    "# Align with STAR\n",
    "# Followd by samtools remove reads with quality less than {qual_cutoff}\n",
    "parameter: qual_cutoff = 10\n",
    "depend: sos_step('star')\n",
    "input: fastq, group_by = 2, concurrent = True\n",
    "output: [f\"{sample_dir}/{x}.qual{qual_cutoff}.bam\" for x in samples], group_by = 1\n",
    "bash: docker_image = 'bschiffthaler/ngs', expand=True\n",
    "    STAR --genomeDir {resource_dir} \\\n",
    "        --genomeFastaFiles {resource_dir}/{ref_fa} \\\n",
    "        --readFilesIn {_input[0]} {_input[1]} \\\n",
    "        --runThreadN {ncpu} --outStd BAM_SortedByCoordinate \\\n",
    "        --outSAMtype BAM SortedByCoordinate \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf} |\n",
    "    samtools view -bq {qual_cutoff} > {_output}\n",
    "\n",
    "[align_2 (WASP intersecting SNP)]\n",
    "# WASP finding unbiased reads intersecting with SNP\n",
    "depends: sos_step('wasp')\n",
    "input: group_by = 1, pattern = '{name}.bam', concurrent = True\n",
    "output: expand_pattern(f'{_name:n}.remap.fq.gz')\n",
    "bash: expand = True\n",
    "    python {wasp_dir}/find_intersecting_snps.py \\\n",
    "        --snp_dir FIXME --is_sorted {_input}\n",
    "\n",
    "[align_3 (STAR prefiltering alignement)]\n",
    "# Align WASP remap with STAR\n",
    "# Followd by samtools remove reads with quality less than {qual_cutoff}\n",
    "parameter: qual_cutoff = 10\n",
    "input: group_by = 1, pattern = '{name}.remap.fq.gz', concurrent = True\n",
    "output: expand_pattern(f'{_name}.wasp.qual{qual_cutoff}.bam')\n",
    "bash: docker_image = 'bschiffthaler/ngs', expand=True\n",
    "    STAR --genomeDir {resource_dir} \\\n",
    "        --genomeFastaFiles {resource_dir}/{ref_fa} \\\n",
    "        --readFilesIn {_input} \\\n",
    "        --readFilesCommand zcat \\\n",
    "        --runThreadN {ncpu} --outStd BAM_SortedByCoordinate \\\n",
    "        --outSAMtype BAM SortedByCoordinate \\\n",
    "        --sjdbGTFtagExonParentTranscript {resource_dir}/{ref_gtf} |\n",
    "    samtools view -bq {qual_cutoff} > {_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = sys.argv[1]\n",
    "list_of_snps = sys.argv[2]\n",
    "nthreads = sys.argv[3]\n",
    "genesymbol = sys.argv[4]\n",
    "genome_folder = sys.argv[5]\n",
    "wasp_path = sys.argv[6]\n",
    "prefix = basename(infile)\n",
    "log_idx = str(int(random.random() * 1000))\n",
    "logfilename = '.'.join([prefix, log_idx, 'log']) \n",
    "logfile = open(logfilename, 'w')\n",
    "print('fastq2bam.' + logfilename + ' is generated')\n",
    "logfile.write('The index is ' + log_idx)\n",
    "logfile.close()\n",
    "\n",
    "cmd = 'mkdir ' + prefix + '_align1'\n",
    "os.system(cmd)\n",
    "\n",
    "# ############################################################\n",
    "# #START# STAR pre-filtering alignment #START#\n",
    "# # input/output:\n",
    "# working_folder1 = prefix + '_align1'\n",
    "# inputfile = infile\n",
    "# outputfile = os.sep.join([working_folder1, 'Aligned.sortedByCoord.out.bam'])\n",
    "# ###\n",
    "# # cmd:\n",
    "# cmd = 'STAR --runThreadN ' + nthreads + ' \\\n",
    "# --genomeDir ' + genome_folder + ' \\\n",
    "# --readFilesIn ' + inputfile + ' \\\n",
    "# --readFilesCommand bzcat \\\n",
    "# --outFileNamePrefix ' + working_folder1 + '/ \\\n",
    "# --outSAMtype BAM SortedByCoordinate \\\n",
    "# --sjdbGTFtagExonParentTranscript ' + genesymbol + ' \\\n",
    "# > ' + outputfile + '.out'\n",
    "# ###\n",
    "# # run cmd\n",
    "# do_and_report(cmd, logfilename, 'STAR-align-prefiltering')\n",
    "# ###\n",
    "# # post step: release memory\n",
    "#  # cmd = 'STAR --genomeLoad Remove'\n",
    "# # do_and_report(cmd, logfilename, 'STAR-align-releasing-memory')\n",
    "# ###\n",
    "# #END# STAR pre-filtering alignment #END#\n",
    "############################################################\n",
    "\n",
    "\n",
    "# ############################################################\n",
    "# #START# samtools removing reads with quuality less than 10 #START#\n",
    "# # input/output:\n",
    "# inputfile = outputfile\n",
    "# outputfile = os.sep.join([working_folder1, 'Aligned.sortedByCoord.out.filtered-quality-10.bam'])\n",
    "# ###\n",
    "# # cmd:\n",
    "# cmd = 'samtools view -bq 10 ' + inputfile + ' > ' + outputfile # here the quality is hard coded as 10\n",
    "# ###\n",
    "# # run cmd:\n",
    "# do_and_report(cmd, logfilename, 'samtools-filter-quality-less-than-10')\n",
    "# ###\n",
    "# #END# STAR pre-filtering alignment #END#\n",
    "############################################################\n",
    "\n",
    "\n",
    "############################################################\n",
    "#START# WASP finding unbiased reads intersecting with SNP #START#\n",
    "# # input/output:\n",
    "# inputfile = outputfile\n",
    "# temp = inputfile.split('.')\n",
    "# wasp_name = basename(inputfile)\n",
    "# wasp_name = wasp_name.split('.')\n",
    "# wasp_name = '.'.join(wasp_name[ : -1])\n",
    "# outputfile = '.'.join(temp[ : -1] + ['remap.fq.gz'])\n",
    "# ###\n",
    "# # cmd:\n",
    "# cmd = 'python-conda ' + wasp_path + '/find_intersecting_snps.py \\\n",
    "# --snp_dir ' + list_of_snps + ' \\\n",
    "# --is_sorted '\\\n",
    "# + inputfile\n",
    "# ###\n",
    "# # run cmd:\n",
    "# do_and_report(cmd, logfilename, 'WASP-intersect-without-bias')\n",
    "###\n",
    "#END# WASP finding unbiased reads intersecting with SNP #END#\n",
    "############################################################\n",
    "\n",
    "# cmd = 'mkdir ' + outputfile + '_align2'\n",
    "# os.system(cmd)\n",
    "\n",
    "############################################################\n",
    "# #START# STAR post-filtering alignment #START#\n",
    "# # input/output:\n",
    "# working_folder2 = outputfile + '_align2'\n",
    "# inputfile = outputfile\n",
    "# outputfile = os.sep.join([working_folder2, 'Aligned.sortedByCoord.out.bam'])\n",
    "# ###\n",
    "# # cmd:\n",
    "# cmd = 'STAR --runThreadN ' + nthreads + ' \\\n",
    "# --genomeDir ' + genome_folder + ' \\\n",
    "# --readFilesIn ' + inputfile + ' \\\n",
    "# --readFilesCommand zcat \\\n",
    "# --outFileNamePrefix ' + working_folder2 + '/ \\\n",
    "# --outSAMtype BAM SortedByCoordinate \\\n",
    "# --sjdbGTFtagExonParentTranscript ' + genesymbol + ' \\\n",
    "# > ' + outputfile + '.out'\n",
    "# ###\n",
    "# # run cmd:\n",
    "# do_and_report(cmd, logfilename, 'STAR-align-postfiltering')\n",
    "# ###\n",
    "# # post step: release memory\n",
    "# # cmd = 'STAR --genomeLoad Remove'\n",
    "# # do_and_report(cmd, logfilename, 'STAR-align-releasing-memory')\n",
    "# ###\n",
    "# #END# STAR post-filtering alignment #END#\n",
    "# ############################################################\n",
    "\n",
    "\n",
    "# ############################################################\n",
    "# #START# samtools removing reads with quuality less than 10 #START#\n",
    "# # input/output:\n",
    "# inputfile = outputfile\n",
    "# outputfile = os.sep.join([working_folder2, 'Aligned.sortedByCoord.out.filtered-quality-10.bam'])\n",
    "# ###\n",
    "# # cmd:\n",
    "# cmd = 'samtools view -bq 10 ' + inputfile + ' > ' + outputfile # here the quality is hard coded as 10\n",
    "# ###\n",
    "# # run cmd:\n",
    "# do_and_report(cmd, logfilename, 'samtools-filter-quality-less-than-10')\n",
    "# ###\n",
    "# #END# STAR pre-filtering alignment #END#\n",
    "# ############################################################\n",
    "\n",
    "\n",
    "############################################################\n",
    "#START# WASP removing ambiguously mapped reads #START#\n",
    "# input/output:\n",
    "inputfile_to_remap = os.sep.join([working_folder1, wasp_name + '.to.remap.bam'])\n",
    "inputfile_keep = os.sep.join([working_folder1, wasp_name + '.keep_remapped.bam'])\n",
    "inputfile_remap = outputfile\n",
    "temp = inputfile.split('.')\n",
    "outputfile = inputfile_keep\n",
    "###\n",
    "# cmd:\n",
    "cmd = 'python-conda ' + wasp_path + '/filter_remapped_reads.py '\\\n",
    "+ inputfile_to_remap + ' '\\\n",
    "+ inputfile_remap + ' '\\\n",
    "+ inputfile_keep\n",
    "###\n",
    "# run cmd:\n",
    "do_and_report(cmd, logfilename, 'WASP-remove-ambiguous-reads')\n",
    "###\n",
    "#END# WASP removing ambiguously mapped reads #END#\n",
    "############################################################\n",
    "\n",
    "\n",
    "############################################################\n",
    "#START# samtools merging kept reads #START#\n",
    "# input/output:\n",
    "inputfile1 = outputfile\n",
    "inputfile2 = os.sep.join([working_folder1, wasp_name + '.keep.bam'])\n",
    "temp = os.sep.join([working_folder1, wasp_name + '.merged_keep.bam'])\n",
    "outputfile = os.sep.join([working_folder1, wasp_name + '.merged_keep.sorted.bam'])\n",
    "###\n",
    "# cmd:\n",
    "cmd = 'samtools merge '\\\n",
    "+ temp + ' '\\\n",
    "+ inputfile1 + ' '\\\n",
    "+ inputfile2\n",
    "###\n",
    "# run cmd:\n",
    "do_and_report(cmd, logfilename, 'samtools-merge-unbiased-reads')\n",
    "###\n",
    "# post step:\n",
    "cmd = 'samtools sort -o '\\\n",
    "+ outputfile + ' '\\\n",
    "+ temp\n",
    "do_and_report(cmd, logfilename, 'samtools-merge-unbiased-reads-sort')\n",
    "cmd = 'samtools index '\\\n",
    "+ outputfile\n",
    "do_and_report(cmd, logfilename, 'samtools-merge-unbiased-reads-index')\n",
    "#END# samtools merging kept reads #END#\n",
    "############################################################\n",
    "\n",
    "\n",
    "############################################################\n",
    "#START# WASP removing duplicated reads randomly #START#\n",
    "# input/output:\n",
    "inputfile = outputfile\n",
    "outputfile = os.sep.join([working_folder1, 'final.bam'])\n",
    "###\n",
    "# cmd:\n",
    "cmd = 'python-conda ' + wasp_path + '/rmdup.py '\\\n",
    "+ inputfile + ' '\\\n",
    "+ outputfile\n",
    "###\n",
    "# run cmd:\n",
    "do_and_report(cmd, logfilename, 'WASP-remove-duplicated-reads')\n",
    "###\n",
    "#END# WASP removing duplicated reads randomly #END#\n",
    "############################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "python3",
     "python3",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0,
    "style": "side"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
